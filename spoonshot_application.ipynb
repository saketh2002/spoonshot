{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "with open('corpus.txt') as f:\n",
        "    contents = f.read()"
      ],
      "metadata": {
        "id": "o45i9W_VLWAE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contents = [contents]"
      ],
      "metadata": {
        "id": "E6IH6u6aLf7X"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from re import sub\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "query_strings = ['Ambrette Seed',\n",
        "'Apple Cinnamon Granola',\n",
        "'Arizona Seasoning',\n",
        "'Americano Coffee',\n",
        "'Baby Abalone',\n",
        "'Cadbury Double Decker Chocolate Bar',\n",
        "'Campari Tomato',\n",
        "'Celery Soup',\n",
        "'Chia Meal',\n",
        "'Crunch Bars',\n",
        "'Cardamom',\n",
        "'Giardiniera',\n",
        "'Hog Maw',\n",
        "'Mccormick Montreal Steak Seasoning',\n",
        "'Muesli',\n",
        "'Mulberry',\n",
        "'Munch Chocolate',\n",
        "'Murukku Packet',\n",
        "'Mango',\n",
        "'Organic Maize',\n",
        "'Organic Peruvian Groundcherry',\n",
        "'Organic Tartar Cream',\n",
        "'Orange Extract',\n",
        "'Pickled Cauliflower',\n",
        "'Pork Chump Chops',\n",
        "'Pork Lungs',\n",
        "'Pork Tripe',\n",
        "'Peanut Butter',\n",
        "'Smokies Sausage',\n",
        "'Snickers Spread',\n",
        "'Strawberry Gelatin',\n",
        "'Salmon',\n",
        "'Tomato',\n",
        "'Tamarind',\n",
        "'Vegan Carob Chips',\n",
        "'Vegan Chicken Strips',\n",
        "'Vegan Chorizo',\n",
        "'Vegan Marshmallow',\n",
        "'Vegan Puff Pastry Sheet',\n",
        "'Vegan Semisweet Chocolate Chips',\n",
        "'Vegan White Cake',\n",
        "'Vegetable Stock',\n",
        "'Vinegar']\n",
        "\n",
        "documents = contents\n",
        "\n",
        "stopwords = ['the', 'and', 'are', 'a']\n",
        "\n",
        "# From: https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/soft_cosine_tutorial.ipynb\n",
        "def preprocess(doc):\n",
        "    # Tokenize, clean up input document string\n",
        "    doc = sub(r'<img[^<>]+(>|$)', \" image_token \", doc)\n",
        "    doc = sub(r'<[^<>]+(>|$)', \" \", doc)\n",
        "    doc = sub(r'\\[img_assist[^]]*?\\]', \" \", doc)\n",
        "    doc = sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', \" url_token \", doc)\n",
        "    return [token for token in simple_preprocess(doc, min_len=0, max_len=float(\"inf\")) if token not in stopwords]\n",
        "\n",
        "# Preprocess the documents, including the query string\n",
        "corpus = [preprocess(document) for document in documents]\n",
        "queries = []\n",
        "for query in query_strings:\n",
        "  queries.append(preprocess(query))"
      ],
      "metadata": {
        "id": "74zb7jr9NHD0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "n_CguvYRNyza",
        "outputId": "aba28824-561c-41d5-b88d-9315679d7ceb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gensim"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mRA-U1VWOH2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import TfidfModel\n",
        "from gensim.similarities import WordEmbeddingSimilarityIndex\n",
        "from gensim.similarities import SparseTermSimilarityMatrix\n",
        "from gensim.similarities import SoftCosineSimilarity\n",
        "\n",
        "# Load the model: this is a big file, can take a while to download and open\n",
        "glove = api.load(\"glove-wiki-gigaword-50\")    \n",
        "similarity_index = WordEmbeddingSimilarityIndex(glove)\n",
        "\n",
        "# Build the term dictionary, TF-idf model\n",
        "for query in queries:\n",
        "  dictionary = Dictionary(corpus+[query])\n",
        "  tfidf = TfidfModel(dictionary=dictionary)\n",
        "\n",
        "# Create the term similarity matrix.  \n",
        "similarity_matrix = SparseTermSimilarityMatrix(similarity_index, dictionary, tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPhrs5L8NeEZ",
        "outputId": "cf03246a-e40e-4890-e1d8-4a4de6380c0d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 420/420 [00:08<00:00, 46.90it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "h78QPmmbPJqb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_similarity_scores = []"
      ],
      "metadata": {
        "id": "bhYN1c-oSp3g"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for query in queries:\n",
        "  query_tf = tfidf[dictionary.doc2bow(query)]\n",
        "\n",
        "  index = SoftCosineSimilarity(\n",
        "              tfidf[[dictionary.doc2bow(document) for document in corpus]],\n",
        "              similarity_matrix)\n",
        "\n",
        "  doc_similarity_scores.append(int(index[query_tf]))\n",
        "print(doc_similarity_scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwjA4ooBO8BM",
        "outputId": "2c0b959d-08ad-4ae2-e4a7-77df966e3958"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array([0.56932014], dtype=float32), array(0., dtype=float32), array([0.7922004], dtype=float32), array(0., dtype=float32), array([0.95291597], dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array([0.99999994], dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array([0.7068612], dtype=float32), array([0.7068612], dtype=float32), array([0.7068612], dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array(0., dtype=float32), array([0.7922004], dtype=float32), array(0., dtype=float32), array([0.92930907], dtype=float32), array([0.92930907], dtype=float32), array([0.92930907], dtype=float32), array([0.92930907], dtype=float32), array([0.92930907], dtype=float32), array([0.92930907], dtype=float32), array([0.92930907], dtype=float32), array(0., dtype=float32), array([0.73247844], dtype=float32), 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Z = [x for _,x in sorted(zip(doc_similarity_scores,query_strings))]\n",
        "print(Z) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIokpQx6SoHv",
        "outputId": "1fbba62e-5456-4ae7-ff7d-a213a3766a5c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Ambrette Seed', 'Americano Coffee', 'Apple Cinnamon Granola', 'Arizona Seasoning', 'Cadbury Double Decker Chocolate Bar', 'Cardamom', 'Celery Soup', 'Crunch Bars', 'Giardiniera', 'Hog Maw', 'Mango', 'Mccormick Montreal Steak Seasoning', 'Muesli', 'Mulberry', 'Murukku Packet', 'Orange Extract', 'Peanut Butter', 'Pickled Cauliflower', 'Pork Chump Chops', 'Pork Lungs', 'Pork Tripe', 'Salmon', 'Smokies Sausage', 'Snickers Spread', 'Strawberry Gelatin', 'Tamarind', 'Vegetable Stock', 'Baby Abalone', 'Organic Maize', 'Organic Peruvian Groundcherry', 'Organic Tartar Cream', 'Vinegar', 'Campari Tomato', 'Tomato', 'Vegan Carob Chips', 'Vegan Chicken Strips', 'Vegan Chorizo', 'Vegan Marshmallow', 'Vegan Puff Pastry Sheet', 'Vegan Semisweet Chocolate Chips', 'Vegan White Cake', 'Chia Meal', 'Munch Chocolate']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#q2\n",
        "\n",
        "def productExceptSelf(a, n):\n",
        " \n",
        "    prod = 1\n",
        "    flag = 0\n",
        " \n",
        "    for i in range(n):\n",
        "        if (a[i] == 0):\n",
        "            flag += 1\n",
        "        else:\n",
        "            prod *= a[i]\n",
        "\n",
        "    arr = [0 for i in range(n)]\n",
        " \n",
        "    for i in range(n):\n",
        "\n",
        "        if (flag > 1):\n",
        "            arr[i] = 0\n",
        "        elif (flag == 0):\n",
        "            arr[i] = (prod // a[i])\n",
        "\n",
        "        elif (flag == 1 and a[i] != 0):\n",
        "            arr[i] = 0\n",
        " \n",
        "        # If(flag == 1 && a[i] == 0)\n",
        "        else:\n",
        "            arr[i] = prod\n",
        " \n",
        "    return arr\n",
        " "
      ],
      "metadata": {
        "id": "KcFDVO67TlcF"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans = productExceptSelf( [5, 1, 4, 2], 4)\n",
        " \n",
        "print(*ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X2zZXtfT5bm",
        "outputId": "c972e679-06b2-40ee-faef-d166fa2894be"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8 40 10 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " ans = productExceptSelf( [1, 0, 3, 4],4)\n",
        " print(*ans)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj96ypU7UExq",
        "outputId": "afd3eb2f-477b-40df-aacf-240137697116"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 12 0 0\n"
          ]
        }
      ]
    }
  ]
}